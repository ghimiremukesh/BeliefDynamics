{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counterfactual Regret Minimization (CFR) and its application to Kuhn Poker\n",
    "\n",
    "\n",
    "Source consulted: https://modelai.gettysburg.edu/2013/cfr/cfr.pdf\n",
    "\n",
    "\n",
    "Kuhn Poker is a simple 3-card poker game created by Harold E. Kuhn. Two players each bet 1 chip blind into the pot before the deal. Three cards (usually K, Q, and J) are suffled, and one card is dealt to each player and held as private information in the original Kuhn Poker game. We implement the game as described in the above paper with additional change as inspired by the [ReBeL](https://arxiv.org/abs/2007.13544) paper. Players do not have any private information -- a referee observes the players' cards and makes decision based on the players' strategy which they announce in the beginning of the game. The players then update their belief based on how the other player's play and simultaneously update their strategy. Further information can be found on the paper.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kuhn_Poker():\n",
    "    \"\"\"\n",
    "    Actions: Pass (0)\n",
    "             Bet  (1)\n",
    "             \n",
    "    Number of Actions: 2\n",
    "    \n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def is_terminal(history):\n",
    "        return history in ['00', '11', '10', '01']\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_payoff(history, cards):\n",
    "        \n",
    "        \"\"\"\n",
    "        payoff structure:\n",
    "        \n",
    "            1) check if both players have had at least one action:\n",
    "                 i) a 'terminal' pass after the first action:\n",
    "                     a) if it is a terminal pass, then a double terminal pass gives 1 chip to \n",
    "                         the player with higher card\n",
    "                     b) if it is single pass after a bet, the player betting wins 1 chip\n",
    "                 \n",
    "                 ii) if not terminal pass, but two consecutive bets, then player with higher card\n",
    "                     gets 2 chips\n",
    "    \n",
    "        \"\"\"\n",
    "        \n",
    "        plays = len(history)\n",
    "        player = len(history[plays-1]) % 2\n",
    "        op = 1 - player\n",
    "        \n",
    "        print(history, plays)\n",
    "        terminal_pass = history[plays-1] == '0'\n",
    "        double_bet = history == '11'\n",
    "        if terminal_pass:\n",
    "            if history == '00':\n",
    "                return 1  if int(cards[player]) > int(cards[op])  else -1\n",
    "            else:\n",
    "                return 1\n",
    "\n",
    "        elif double_bet:\n",
    "            return 2 if int(cards[player]) > int(cards[op]) else -2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Info_Set():\n",
    "    \"\"\"\n",
    "    Action-observation history of the game\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.regret_sum = np.zeros(shape=2)\n",
    "        self.strategy = np.zeros(shape=2)\n",
    "        self.strategy_sum = np.zeros(shape=2) \n",
    "    \n",
    "    def normalize(self):\n",
    "        \"\"\"\n",
    "        Normalize the strategy to (0, 1). If the regrets are negative, return uniform strategy.\n",
    "        \n",
    "        \"\"\"\n",
    "        if sum(self.strategy) > 0:\n",
    "            self.strategy /= np.sum(self.strategy)\n",
    "        else:\n",
    "            self.strategy = np.ones(2)/2\n",
    "        \n",
    "        return self.strategy\n",
    "    \n",
    "    def get_strategy(self, reach_prob):\n",
    "        self.strategy = np.maximum(0, self.regret_sum)\n",
    "        self.normalize() \n",
    "        \n",
    "        self.strategy_sum = reach_prob * self.strategy\n",
    "        \n",
    "        return self.strategy\n",
    "    \n",
    "    def get_average_strategy(self):\n",
    "        return self.strategy_sum/np.sum(self.strategy_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFRTrainer():\n",
    "    def __init__(self):\n",
    "        self.infoset_map: Dict[str, Info_Set] = {}\n",
    "            \n",
    "    def get_info_set(self, history):\n",
    "        \"\"\"\n",
    "        return the history while adding if needed\n",
    "        \n",
    "        \"\"\"\n",
    "        if history not in self.infoset_map:\n",
    "            self.infoset_map[history] = Info_Set()\n",
    "            \n",
    "        return self.infoset_map[history]\n",
    "    \n",
    "    def cfr(self, cards, history, reach_prob, current_player):\n",
    "        if Kuhn_Poker.is_terminal(history):\n",
    "            return Kuhn_Poker.get_payoff(history, cards)\n",
    "        \n",
    "        my_card = cards[current_player]\n",
    "        info_set = self.get_info_set(history + my_card)\n",
    "        \n",
    "        strategy = info_set.get_strategy(reach_prob[current_player])\n",
    "        op = (current_player + 1)%2\n",
    "        cfr_values = np.zeros(2)\n",
    "        \n",
    "        for action in range(2):\n",
    "            action_prob = strategy[action]\n",
    "            \n",
    "            # compute new_reach_probabilities for this action\n",
    "            new_reach_prob = reach_prob.copy()\n",
    "            new_reach_prob[current_player] *= action_prob\n",
    "            \n",
    "            # call CFR recursively with next player to act as opponent\n",
    "            \n",
    "            cfr_values[action] = -1*self.cfr(cards, history + str(action), new_reach_prob, op)\n",
    "            \n",
    "        # value of the current node is counterfactual values * action probabilities\n",
    "        node_value = cfr_values.dot(strategy)\n",
    "        \n",
    "        for action in range(2):\n",
    "            info_set.regret_sum += reach_prob[op] * (cfr_values[action] - node_value)\n",
    "        \n",
    "        return node_value     \n",
    "    \n",
    "    def train(self, num_iter):\n",
    "        util = 0\n",
    "        K_cards = ['0', '1', '2'] # J, Q, K\n",
    "        for _ in range(num_iter):\n",
    "            cards = random.sample(K_cards, 2)\n",
    "            history = ''\n",
    "            reach_prob = np.ones(2)\n",
    "            util += self.cfr(cards, history, reach_prob, 0)\n",
    "        return util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "Actions = ['B', 'C']  # bet/call vs check/fold\n",
    "\n",
    "class InformationSet():\n",
    "    def __init__(self):\n",
    "        self.cumulative_regrets = np.zeros(shape=len(Actions))\n",
    "        self.strategy_sum = np.zeros(shape=len(Actions))\n",
    "        self.num_actions = len(Actions)\n",
    "\n",
    "    def normalize(self, strategy: np.array) -> np.array:\n",
    "        \"\"\"Normalize a strategy. If there are no positive regrets,\n",
    "        use a uniform random strategy\"\"\"\n",
    "        if sum(strategy) > 0:\n",
    "            strategy /= sum(strategy)\n",
    "        else:\n",
    "            strategy = np.array([1.0 / self.num_actions] * self.num_actions)\n",
    "        return strategy\n",
    "\n",
    "    def get_strategy(self, reach_probability: float) -> np.array:\n",
    "        \"\"\"Return regret-matching strategy\"\"\"\n",
    "        strategy = np.maximum(0, self.cumulative_regrets)\n",
    "        strategy = self.normalize(strategy)\n",
    "\n",
    "        self.strategy_sum += reach_probability * strategy\n",
    "        return strategy\n",
    "\n",
    "    def get_average_strategy(self) -> np.array:\n",
    "        return self.normalize(self.strategy_sum.copy())\n",
    "\n",
    "\n",
    "class KuhnPoker():\n",
    "    @staticmethod\n",
    "    def is_terminal(history: str) -> bool:\n",
    "        return history in ['BC', 'BB', 'CC', 'CBB', 'CBC']\n",
    "\n",
    "    @staticmethod\n",
    "    def get_payoff(history: str, cards: List[str]) -> int:\n",
    "        \"\"\"get payoff for 'active' player in terminal history\"\"\"\n",
    "        if history in ['BC', 'CBC']:\n",
    "            return +1\n",
    "        else:  # CC or BB or CBB\n",
    "            payoff = 2 if 'B' in history else 1\n",
    "            active_player = len(history) % 2\n",
    "            player_card = cards[active_player]\n",
    "            opponent_card = cards[(active_player + 1) % 2]\n",
    "            if player_card == 'K' or opponent_card == 'J':\n",
    "                return payoff\n",
    "            else:\n",
    "                return -payoff\n",
    "\n",
    "\n",
    "class KuhnCFRTrainer():\n",
    "    def __init__(self):\n",
    "        self.infoset_map: Dict[str, InformationSet] = {}\n",
    "\n",
    "    def get_information_set(self, card_and_history: str) -> InformationSet:\n",
    "        \"\"\"add if needed and return\"\"\"\n",
    "        if card_and_history not in self.infoset_map:\n",
    "            self.infoset_map[card_and_history] = InformationSet()\n",
    "        return self.infoset_map[card_and_history]\n",
    "\n",
    "    def cfr(self, cards: List[str], history: str, reach_probabilities: np.array, active_player: int):\n",
    "        if KuhnPoker.is_terminal(history):\n",
    "            return KuhnPoker.get_payoff(history, cards)\n",
    "\n",
    "        my_card = cards[active_player]\n",
    "        info_set = self.get_information_set(my_card + history)\n",
    "\n",
    "        strategy = info_set.get_strategy(reach_probabilities[active_player])\n",
    "        opponent = (active_player + 1) % 2\n",
    "        counterfactual_values = np.zeros(len(Actions))\n",
    "\n",
    "        for ix, action in enumerate(Actions):\n",
    "            action_probability = strategy[ix]\n",
    "\n",
    "            # compute new reach probabilities after this action\n",
    "            new_reach_probabilities = reach_probabilities.copy()\n",
    "            new_reach_probabilities[active_player] *= action_probability\n",
    "\n",
    "            # recursively call cfr method, next player to act is the opponent\n",
    "            counterfactual_values[ix] = -self.cfr(cards, history + action, new_reach_probabilities, opponent)\n",
    "\n",
    "        # Value of the current game state is just counterfactual values weighted by action probabilities\n",
    "        node_value = counterfactual_values.dot(strategy)\n",
    "        for ix, action in enumerate(Actions):\n",
    "            info_set.cumulative_regrets[ix] += reach_probabilities[opponent] * (counterfactual_values[ix] - node_value)\n",
    "\n",
    "        return node_value\n",
    "\n",
    "    def train(self, num_iterations: int) -> int:\n",
    "        util = 0\n",
    "        kuhn_cards = ['J', 'Q', 'K']\n",
    "        for _ in range(num_iterations):\n",
    "            cards = random.sample(kuhn_cards, 2)\n",
    "            history = ''\n",
    "            reach_probabilities = np.ones(2)\n",
    "            util += self.cfr(cards, history, reach_probabilities, 0)\n",
    "        return util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Kuhn Poker chance sampling CFR for 1000 iterations\n",
      "\n",
      "Expected average game value (for player 1): -0.056\n",
      "Computed average game value               : -0.064\n",
      "\n",
      "We expect the bet frequency for a Jack to be between 0 and 1/3\n",
      "The bet frequency of a King should be three times the one for a Jack\n",
      "\n",
      "History  Bet  Pass\n",
      "K  :    [0.78358663 0.21641337]\n",
      "J  :    [0.25143939 0.74856061]\n",
      "Q  :    [0.06002032 0.93997968]\n",
      "QB :    [0.42524923 0.57475077]\n",
      "QC :    [0.01391304 0.98608696]\n",
      "JB :    [0.00154799 0.99845201]\n",
      "JC :    [0.33576608 0.66423392]\n",
      "KB :    [0.99849398 0.00150602]\n",
      "KC :    [0.99849398 0.00150602]\n",
      "KCB:    [0.99646729 0.00353271]\n",
      "JCB:    [9.48790609e-04 9.99051209e-01]\n",
      "QCB:    [0.59656809 0.40343191]\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 1000\n",
    "cfr_trainer = KuhnCFRTrainer()\n",
    "util = cfr_trainer.train(num_iterations)\n",
    "\n",
    "print(f\"\\nRunning Kuhn Poker chance sampling CFR for {num_iterations} iterations\")\n",
    "print(f\"\\nExpected average game value (for player 1): {(-1./18):.3f}\")\n",
    "print(f\"Computed average game value               : {(util / num_iterations):.3f}\\n\")\n",
    "\n",
    "print(\"We expect the bet frequency for a Jack to be between 0 and 1/3\")\n",
    "print(\"The bet frequency of a King should be three times the one for a Jack\\n\")\n",
    "\n",
    "print(f\"History  Bet  Pass\")\n",
    "for name, info_set in sorted(cfr_trainer.infoset_map.items(), key=lambda s: len(s[0])):\n",
    "    print(f\"{name:3}:    {info_set.get_average_strategy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
