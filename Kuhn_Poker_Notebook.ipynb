{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counterfactual Regret Minimization (CFR) and its application to Kuhn Poker\n",
    "\n",
    "\n",
    "Source consulted: https://modelai.gettysburg.edu/2013/cfr/cfr.pdf\n",
    "\n",
    "\n",
    "Kuhn Poker is a simple 3-card poker game created by Harold E. Kuhn. Two players each bet 1 chip blind into the pot before the deal. Three cards (usually K, Q, and J) are suffled, and one card is dealt to each player and held as private information in the original Kuhn Poker game. We implement the game as described in the above paper with additional change as inspired from the [ReBeL](https://arxiv.org/abs/2007.13544) paper. Players do not have any private information -- a referee observes the players' cards and makes decision based on the players' strategy which they announce in the beginning of the game. The players then update their belief based on how the other player's play and simultaneously update their strategy. Further information can be found on the paper.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kuhn_Poker():\n",
    "    \"\"\"\n",
    "    Actions: Pass (0)\n",
    "             Bet  (1)\n",
    "             \n",
    "    Number of Actions: 2\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.kPass = 0\n",
    "        self.kBet = 1\n",
    "        self.num_actions = 2\n",
    "        self.infoset = InfoSet()\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_terminal(history):\n",
    "        \n",
    "        return history in ['00', '11', '10', '01']\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_payoff(history, cards):\n",
    "        \n",
    "        \"\"\"\n",
    "        payoff structure:\n",
    "        \n",
    "            1) check if both players have had at least one action:\n",
    "                 i) a 'terminal' pass after the first action:\n",
    "                     a) if it is a terminal pass, then a double terminal pass gives 1 chip to \n",
    "                         the player with higher card\n",
    "                     b) if it is single pass after a bet, the player betting wins 1 chip\n",
    "                 \n",
    "                 ii) if not terminal pass, but two consecutive bets, then player with higher card\n",
    "                     gets 2 chips\n",
    "    \n",
    "        \"\"\"\n",
    "        \n",
    "        plays = len(history)\n",
    "        player = len(history[plays-1]) % 2\n",
    "        op = 1 - player\n",
    "        \n",
    "        if is_terminal(history):\n",
    "            terminalPass = history[plays-1][1] == '0'\n",
    "            doubleBet = history[plays-1] == '11'\n",
    "            if terminalPass:\n",
    "                if history[plays-1] == '00':\n",
    "                    return 1  if cards[player] > cards[op]  else -1\n",
    "                else:\n",
    "                    return 1\n",
    "            \n",
    "            elif doubleBet:\n",
    "                return 2 if cards[player] > cards[op] else -2\n",
    "        \n",
    "\n",
    "class InfoSet():\n",
    "    \"\"\"\n",
    "    Action-observation history of the game\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.regretSum = np.zeros(shape=2)\n",
    "        self.strategy = np.zeros(shape=2)\n",
    "        self.strategySum = np.zeros(shape=2) \n",
    "    \n",
    "    def normalize(self):\n",
    "        \"\"\"\n",
    "        Normalize the strategy to (0, 1). If the regrets are negative, return uniform strategy.\n",
    "        \n",
    "        \"\"\"\n",
    "        if sum(self.strategy) > 0:\n",
    "            self.strategy /= sum(self.strategy)\n",
    "        else:\n",
    "            self.strategy = np.ones(2)/2\n",
    "        \n",
    "        return self.strategy\n",
    "    \n",
    "    def getStrategy(self, reach_prob):\n",
    "        self.strategy = np.max(0, self.regretSum)\n",
    "        self.normalize() \n",
    "        \n",
    "        self.strategySum = reach_prob * self.strategy\n",
    "        \n",
    "        return self.strategy\n",
    "    \n",
    "    def getAverageStrategy(self):\n",
    "        return self.strategySum/sum(self.strategySum)\n",
    " \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
