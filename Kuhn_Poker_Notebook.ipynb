{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counterfactual Regret Minimization (CFR) and its application to Kuhn Poker\n",
    "\n",
    "\n",
    "Source consulted: https://modelai.gettysburg.edu/2013/cfr/cfr.pdf\n",
    "\n",
    "\n",
    "Kuhn Poker is a simple 3-card poker game created by Harold E. Kuhn. Two players each bet 1 chip blind into the pot before the deal. Three cards (usually K, Q, and J) are suffled, and one card is dealt to each player and held as private information in the original Kuhn Poker game. We implement the game as described in the above paper with additional change as inspired by the [ReBeL](https://arxiv.org/abs/2007.13544) paper. Players do not have any private information -- a referee observes the players' cards and makes decision based on the players' strategy which they announce in the beginning of the game. The players then update their belief based on how the other player's play and simultaneously update their strategy. Further information can be found on the paper.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## source: https://ai.plainenglish.io/building-a-poker-ai-part-6-beating-kuhn-poker-with-cfr-using-python-1b4172a6ab2d\n",
    "\n",
    "from typing import List, Dict\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "Actions = ['B', 'C']  # bet/call vs check/fold\n",
    "\n",
    "class InformationSet():\n",
    "    def __init__(self):\n",
    "        self.cumulative_regrets = np.zeros(shape=len(Actions))\n",
    "        self.strategy_sum = np.zeros(shape=len(Actions))\n",
    "        self.num_actions = len(Actions)\n",
    "\n",
    "    def normalize(self, strategy: np.array) -> np.array:\n",
    "        \"\"\"Normalize a strategy. If there are no positive regrets,\n",
    "        use a uniform random strategy\"\"\"\n",
    "        if sum(strategy) > 0:\n",
    "            strategy /= sum(strategy)\n",
    "        else:\n",
    "            strategy = np.array([1.0 / self.num_actions] * self.num_actions)\n",
    "        return strategy\n",
    "\n",
    "    def get_strategy(self, reach_probability: float) -> np.array:\n",
    "        \"\"\"Return regret-matching strategy\"\"\"\n",
    "        strategy = np.maximum(0, self.cumulative_regrets)\n",
    "        strategy = self.normalize(strategy)\n",
    "\n",
    "        self.strategy_sum += reach_probability * strategy\n",
    "        return strategy\n",
    "\n",
    "    def get_average_strategy(self) -> np.array:\n",
    "        return self.normalize(self.strategy_sum.copy())\n",
    "\n",
    "\n",
    "class KuhnPoker():\n",
    "    @staticmethod\n",
    "    def is_terminal(history: str) -> bool:\n",
    "        return history in ['BC', 'BB', 'CC', 'CBB', 'CBC']  # in cases where player 1 \n",
    "\n",
    "    @staticmethod\n",
    "    def get_payoff(history: str, cards: List[str]) -> int:\n",
    "        \"\"\"get payoff for 'active' player in terminal history\"\"\"\n",
    "        if history in ['BC', 'CBC']:\n",
    "            return +1\n",
    "        else:  # CC or BB or CBB\n",
    "            payoff = 2 if 'B' in history else 1\n",
    "            active_player = len(history) % 2\n",
    "            player_card = cards[active_player]\n",
    "            opponent_card = cards[(active_player + 1) % 2]\n",
    "            if player_card == 'K' or opponent_card == 'J':\n",
    "                return payoff\n",
    "            else:\n",
    "                return -payoff\n",
    "\n",
    "\n",
    "class KuhnCFRTrainer_NoRebel():\n",
    "    def __init__(self):\n",
    "        self.infoset_map: Dict[str, InformationSet] = {}\n",
    "        self.current_average_strategy = np.array([0.5, 0.5]) # keep track of strategies, initialize with 50% bet, 50% pass\n",
    "\n",
    "    def get_information_set(self, card_and_history: str) -> InformationSet:\n",
    "        \"\"\"add if needed and return\"\"\"\n",
    "        if card_and_history not in self.infoset_map:\n",
    "            self.infoset_map[card_and_history] = InformationSet()\n",
    "        return self.infoset_map[card_and_history]\n",
    "\n",
    "    def cfr(self, cards: List[str], history: str, reach_probabilities: np.array, active_player: int):\n",
    "        if KuhnPoker.is_terminal(history):\n",
    "            return KuhnPoker.get_payoff(history, cards)\n",
    "\n",
    "        my_card = cards[active_player]\n",
    "        info_set = self.get_information_set(my_card + history)\n",
    "\n",
    "        strategy = info_set.get_strategy(reach_probabilities[active_player])\n",
    "        \n",
    "#         ####### CFR-AVG modification as per Rebel #############\n",
    "#         strategy = (self.current_average_strategy + strategy)/2   # current strategy is not the last strategy, instead its \n",
    "#                                                                   # the current average strategy.\n",
    "#         self.current_average_strategy = strategy\n",
    "#         ########################################################\n",
    "        opponent = (active_player + 1) % 2\n",
    "        counterfactual_values = np.zeros(len(Actions))\n",
    "\n",
    "        for ix, action in enumerate(Actions):\n",
    "            action_probability = strategy[ix]\n",
    "\n",
    "            # compute new reach probabilities after this action\n",
    "            new_reach_probabilities = reach_probabilities.copy()\n",
    "            new_reach_probabilities[active_player] *= action_probability\n",
    "\n",
    "            # recursively call cfr method, next player to act is the opponent\n",
    "            counterfactual_values[ix] = -self.cfr(cards, history + action, new_reach_probabilities, opponent)\n",
    "\n",
    "        # Value of the current game state is just counterfactual values weighted by action probabilities\n",
    "        node_value = counterfactual_values.dot(strategy)\n",
    "        for ix, action in enumerate(Actions):\n",
    "            \n",
    "            info_set.cumulative_regrets[ix] += reach_probabilities[opponent] * (counterfactual_values[ix] - node_value)\n",
    "\n",
    "        return node_value\n",
    "\n",
    "    def train(self, num_iterations: int) -> int:\n",
    "        util = 0\n",
    "        kuhn_cards = ['J', 'Q', 'K']\n",
    "        for _ in range(num_iterations):\n",
    "            cards = random.sample(kuhn_cards, 2)\n",
    "            history = ''\n",
    "            reach_probabilities = np.ones(2)\n",
    "            util += self.cfr(cards, history, reach_probabilities, 0)\n",
    "        return util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THINK IN TERMS OF REBEL\n",
    "\n",
    "1. Players only have some belief over their current card: \n",
    "\n",
    "<!-- C(P_1) = [1/3, 1/3, 1/3]  -- Player 1's probability of getting each card | could be K, Q, or J\n",
    "C(P_2) = [1/2, 1/2]       -- Player 2's probability of getting remaining card | conditioned over player 1's action -->\n",
    "\n",
    "2. Players share same belief as it is assumed that players actually \"know the best policy\". \n",
    "    \\begin{aligned}\n",
    "        \\text{belief} &= \\begin{pmatrix} argmax\\big(P(K), P(Q), P(J)\\big) \\\\\n",
    "                    argmax\\big(P(K), P(Q), P(J)\\big) \\end{pmatrix}\n",
    "    \\end{aligned}\n",
    "\n",
    "3. The infostate (here, infoset) then becomes strings of belief + action \n",
    "\n",
    "\n",
    "4. History is just a string of cards (we omit legal actions because player can always pick either pass(call)/bet\n",
    "\n",
    "\n",
    "\n",
    "### How to condition belief?  based on history ? \n",
    "\n",
    "-- If history is not empty:\n",
    "                \n",
    "                -- check last action : if bet --> likely had a better card. --> update belief \n",
    "--  If empty:\n",
    "      \n",
    "                -- use current belief (initial random??)\n",
    "                \n",
    "\n",
    "-------------------------------\n",
    "\n",
    "**Try Implementing these below**\n",
    "\n",
    "_______________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kuhn_cards = ['J', 'Q', 'K']\n",
    "random.sample(kuhn_cards, 2)\n",
    "\n",
    "probs = np.ones((2,3))/3\n",
    "\n",
    "tostring = lambda x: kuhn_cards[x[0]] + kuhn_cards[x[1]]\n",
    "\n",
    "cards = np.argmax(probs, axis = 1)\n",
    "cards = tostring(cards)\n",
    "\n",
    "\n",
    "## update belief\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JJ'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## source: https://ai.plainenglish.io/building-a-poker-ai-part-6-beating-kuhn-poker-with-cfr-using-python-1b4172a6ab2d\n",
    "\n",
    "from typing import List, Dict\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "Actions = ['B', 'C']  # bet/call vs check/fold\n",
    "\n",
    "class InformationSet():\n",
    "    def __init__(self):\n",
    "        self.cumulative_regrets = np.zeros(shape=len(Actions))\n",
    "        self.strategy_sum = np.zeros(shape=len(Actions))\n",
    "        self.num_actions = len(Actions)\n",
    "\n",
    "    def normalize(self, strategy: np.array) -> np.array:\n",
    "        \"\"\"Normalize a strategy. If there are no positive regrets,\n",
    "        use a uniform random strategy\"\"\"\n",
    "        if sum(strategy) > 0:\n",
    "            strategy /= sum(strategy)\n",
    "        else:\n",
    "            strategy = np.array([1.0 / self.num_actions] * self.num_actions)\n",
    "        return strategy\n",
    "\n",
    "    def get_strategy(self, reach_probability: float) -> np.array:\n",
    "        \"\"\"Return regret-matching strategy\"\"\"\n",
    "        strategy = np.maximum(0, self.cumulative_regrets)\n",
    "        strategy = self.normalize(strategy)\n",
    "\n",
    "        self.strategy_sum += reach_probability * strategy\n",
    "        return strategy\n",
    "\n",
    "    def get_average_strategy(self) -> np.array:\n",
    "        return self.normalize(self.strategy_sum.copy())\n",
    "\n",
    "\n",
    "class KuhnPoker():\n",
    "    @staticmethod\n",
    "    def is_terminal(history: str) -> bool:\n",
    "        return history in ['BC', 'BB', 'CC', 'CBB', 'CBC']  # in cases where player 1 \n",
    "\n",
    "    @staticmethod\n",
    "    def get_payoff(history: str, cards: List[str]) -> int:\n",
    "        \"\"\"get payoff for 'active' player in terminal history\"\"\"\n",
    "        if history in ['BC', 'CBC']:\n",
    "            return +1\n",
    "        else:  # CC or BB or CBB\n",
    "            payoff = 2 if 'B' in history else 1\n",
    "            active_player = len(history) % 2\n",
    "            player_card = cards[active_player]\n",
    "            opponent_card = cards[(active_player + 1) % 2]\n",
    "            if player_card == 'K' or opponent_card == 'J':\n",
    "                return payoff\n",
    "            else:\n",
    "                return -payoff\n",
    "\n",
    "\n",
    "class KuhnCFRTrainer():\n",
    "    def __init__(self):\n",
    "        self.infoset_map: Dict[str, InformationSet] = {}\n",
    "        self.current_average_strategy = np.array([0.5, 0.5]) # keep track of strategies, initialize with 50% bet, 50% pass\n",
    "\n",
    "    def get_information_set(self, card_and_history: str) -> InformationSet:\n",
    "        \"\"\"add if needed and return\"\"\"\n",
    "        if card_and_history not in self.infoset_map:\n",
    "            self.infoset_map[card_and_history] = InformationSet()\n",
    "        return self.infoset_map[card_and_history]\n",
    "\n",
    "    def cfr(self, cards: List[str], history: str, reach_probabilities: np.array, active_player: int):\n",
    "        if KuhnPoker.is_terminal(history):\n",
    "            return KuhnPoker.get_payoff(history, cards)\n",
    "        \n",
    "        opponent = (active_player + 1) % 2\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### BELIEF UPDATE --- SIMPLE IMPLEMENTATION FOR CONCEPT DEMONSTRATION\n",
    "        \n",
    "        if not(history == ''):\n",
    "            last_action = history[len(history)-1]\n",
    "            \n",
    "            if last_action == 'B':  # opponent likely has better card\n",
    "                dist = [0.1, 0.3, 0.6]\n",
    "                cards[opponent] = np.random.choice(kuhn_cards, p=dist)\n",
    "                cards[active_player] = np.random.choice([c for c in kuhn_cards if c != cards[opponent]])\n",
    "            elif last_action =='C': # opponent likely has bad card\n",
    "                dist = [0.6, 0.3, 0.1]\n",
    "                cards[opponent] = np.random.choice(kuhn_cards, p=dist)\n",
    "                cards[active_player] = np.random.choice([c for c in kuhn_cards if c != cards[opponent]])\n",
    "\n",
    "        my_card = cards[active_player]\n",
    "        info_set = self.get_information_set(my_card + history)\n",
    "\n",
    "        strategy = info_set.get_strategy(reach_probabilities[active_player])\n",
    "        \n",
    "        ####### CFR-AVG modification as per Rebel #############\n",
    "        strategy = (self.current_average_strategy + strategy)/2   # current strategy is not the last strategy, instead its \n",
    "                                                                  # the current average strategy.\n",
    "        self.current_average_strategy = strategy\n",
    "        ########################################################\n",
    "        #opponent = (active_player + 1) % 2\n",
    "        counterfactual_values = np.zeros(len(Actions))\n",
    "\n",
    "        for ix, action in enumerate(Actions):\n",
    "            action_probability = strategy[ix]\n",
    "\n",
    "            # compute new reach probabilities after this action\n",
    "            new_reach_probabilities = reach_probabilities.copy()\n",
    "            new_reach_probabilities[active_player] *= action_probability\n",
    "\n",
    "            # recursively call cfr method, next player to act is the opponent\n",
    "            counterfactual_values[ix] = -self.cfr(cards, history + action, new_reach_probabilities, opponent)\n",
    "\n",
    "        # Value of the current game state is just counterfactual values weighted by action probabilities\n",
    "        node_value = counterfactual_values.dot(strategy)\n",
    "        for ix, action in enumerate(Actions):\n",
    "            \n",
    "            info_set.cumulative_regrets[ix] += reach_probabilities[opponent] * (counterfactual_values[ix] - node_value)\n",
    "\n",
    "        return node_value\n",
    "\n",
    "        for ix, action in enumerate(Actions):\n",
    "            action_probability = strategy[ix]\n",
    "\n",
    "            # compute new reach probabilities after this action\n",
    "            new_reach_probabilities = reach_probabilities.copy()\n",
    "            new_reach_probabilities[active_player] *= action_probability\n",
    "\n",
    "            # recursively call cfr method, next player to act is the opponent\n",
    "            counterfactual_values[ix] = -self.cfr(cards, history + action, new_reach_probabilities, opponent)\n",
    "\n",
    "        # Value of the current game state is just counterfactual values weighted by action probabilities\n",
    "        node_value = counterfactual_values.dot(strategy)\n",
    "        for ix, action in enumerate(Actions):\n",
    "            \n",
    "            info_set.cumulative_regrets[ix] += reach_probabilities[opponent] * (counterfactual_values[ix] - node_value)\n",
    "\n",
    "        return node_value\n",
    "    \n",
    "    \n",
    "    def train(self, num_iterations: int) -> int:\n",
    "        util = 0\n",
    "        kuhn_cards = ['J', 'Q', 'K']\n",
    "        actual = []\n",
    "        beliefs = []\n",
    "        \n",
    "        for _ in range(num_iterations):\n",
    "            actual_cards = random.sample(kuhn_cards, 2)\n",
    "            actual.append(actual_cards) # keep track of cards\n",
    "            \n",
    "#             probs = np.random.rand(2,3)  # initial belief -- not quite correct - need to come up with something robust\n",
    "#             belief = np.argmax(probs, axis = 1)\n",
    "#             belief = tostring(belief)\n",
    "#             beliefs.append(belief)\n",
    "            \n",
    "            i_dist = np.ones(len(kuhn_cards))/len(kuhn_cards)\n",
    "\n",
    "            belief = np.random.choice(kuhn_cards, size = 2, p=i_dist)\n",
    "            beliefs.append(belief)\n",
    "            \n",
    "            history = ''\n",
    "            reach_probabilities = np.ones(2)\n",
    "            util += self.cfr(belief, history, reach_probabilities, 0)  # cfr w/belief\n",
    "        \n",
    "        return util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------CFR w/o ReBeL Implementation---------------------------------\n",
      "\n",
      "Running Kuhn Poker chance sampling CFR for 1000 iterations\n",
      "\n",
      "Expected average game value (for player 1): -0.056\n",
      "Computed average game value               : -0.015\n",
      "\n",
      "We expect the bet frequency for a Jack to be between 0 and 1/3\n",
      "The bet frequency of a King should be three times the one for a Jack\n",
      "\n",
      "History  Bet  Pass\n",
      "K  :    [0.76897653 0.23102347]\n",
      "Q  :    [0.08165009 0.91834991]\n",
      "J  :    [0.13465637 0.86534363]\n",
      "QB :    [0.37723185 0.62276815]\n",
      "QC :    [0.00901548 0.99098452]\n",
      "KB :    [0.99837134 0.00162866]\n",
      "KC :    [0.99837134 0.00162866]\n",
      "JB :    [0.00144092 0.99855908]\n",
      "JC :    [0.31021867 0.68978133]\n",
      "KCB:    [0.99686336 0.00313664]\n",
      "QCB:    [0.66699756 0.33300244]\n",
      "JCB:    [9.11364584e-04 9.99088635e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------CFR w ReBeL Implementation---------------------------------\n",
      "\n",
      "Computed average game value               : 0.393\n",
      "\n",
      "We expect the bet frequency for a Jack to be between 0 and 1/3\n",
      "The bet frequency of a King should be three times the one for a Jack\n",
      "\n",
      "History  Bet  Pass\n",
      "Q  :    [0.99842767 0.00157233]\n",
      "K  :    [0.99857955 0.00142045]\n",
      "J  :    [0.99848485 0.00151515]\n",
      "QB :    [0.02233949 0.97766051]\n",
      "QC :    [0.99501429 0.00498571]\n",
      "KB :    [0.99731183 0.00268817]\n",
      "JC :    [0.99725275 0.00274725]\n",
      "JB :    [0.00110132 0.99889868]\n",
      "KC :    [0.9989154 0.0010846]\n",
      "JCB:    [0.0020235 0.9979765]\n",
      "KCB:    [0.99683322 0.00316678]\n",
      "QCB:    [0.00995737 0.99004263]\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 1000\n",
    "cfr_trainer_rebel = KuhnCFRTrainer()\n",
    "cfr_trainer = KuhnCFRTrainer_NoRebel()\n",
    "util_Rebel = cfr_trainer_rebel.train(num_iterations)\n",
    "util_NoRebel = cfr_trainer.train(num_iterations)\n",
    "\n",
    "\n",
    "print('------------CFR w/o ReBeL Implementation---------------------------------')\n",
    "print(f\"\\nRunning Kuhn Poker chance sampling CFR for {num_iterations} iterations\")\n",
    "print(f\"\\nExpected average game value (for player 1): {(-1./18):.3f}\")\n",
    "print(f\"Computed average game value               : {(util_NoRebel / num_iterations):.3f}\\n\")\n",
    "\n",
    "print(\"We expect the bet frequency for a Jack to be between 0 and 1/3\")\n",
    "print(\"The bet frequency of a King should be three times the one for a Jack\\n\")\n",
    "\n",
    "print(f\"History  Bet  Pass\")\n",
    "for name, info_set in sorted(cfr_trainer.infoset_map.items(), key=lambda s: len(s[0])):\n",
    "    print(f\"{name:3}:    {info_set.get_average_strategy()}\")\n",
    "    \n",
    "print(\"\\n\\n\\n\")\n",
    "    \n",
    "print('------------CFR w ReBeL Implementation---------------------------------')\n",
    "print(f\"\\nComputed average game value               : {(util_Rebel / num_iterations):.3f}\\n\")\n",
    "\n",
    "print(\"We expect the bet frequency for a Jack to be between 0 and 1/3\")\n",
    "print(\"The bet frequency of a King should be three times the one for a Jack\\n\")\n",
    "\n",
    "print(f\"History  Bet  Pass\")\n",
    "for name, info_set in sorted(cfr_trainer_rebel.infoset_map.items(), key=lambda s: len(s[0])):\n",
    "    print(f\"{name:3}:    {info_set.get_average_strategy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'J'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
